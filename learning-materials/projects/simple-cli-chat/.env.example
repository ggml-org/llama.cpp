# Example Environment Variables for Simple CLI Chat
# Copy this file to .env and customize as needed

# Path to llama.cpp executable
LLAMA_CPP_PATH=./llama-cli

# Default model path
MODEL_PATH=./models/llama-2-7b-chat.Q4_K_M.gguf

# Default context size
CONTEXT_SIZE=2048

# Number of threads
THREADS=4

# GPU layers (0 for CPU only)
GPU_LAYERS=0
