# .cirrus.yml
# Cirrus CI Configuration for Llama.cpp Quantization Benchmarks

env:
  MODEL_REPO: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'
  MODEL_NAME: 'tinyllama-1.1b'

benchmark_arm_task:
  # Free high-performance ARM container (up to 4 CPU cores, 16GB RAM)
  arm_container:
    image: ubuntu:22.04
    cpu: 4
    memory: 16G
  
  timeout_in: 120m

  # Install required dependencies
  install_script: |
    apt-get update
    apt-get install -y cmake build-essential python3-pip curl unzip make bc
    pip3 install torch transformers sentencepiece protobuf safetensors "huggingface_hub[cli]" --break-system-packages

  # Build the project
  build_script: |
    cmake -B build -DGGML_NATIVE=OFF -DGGML_METAL=OFF -DGGML_CUDA=OFF
    cmake --build build --target llama-quantize llama-perplexity llama-bench -j$(nproc)

  # Download model and dataset
  download_script: |
    python3 -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='${MODEL_REPO}', local_dir='models/hf-model')"
    python3 convert_hf_to_gguf.py models/hf-model --outfile models/model-F16.gguf --outtype f16
    
    curl -L "https://huggingface.co/datasets/ggml-org/ci/resolve/main/wikitext-2-raw-v1.zip" -o models/wikitext-2-raw.zip
    cd models && unzip -o wikitext-2-raw.zip

  # Quantize to all types
  quantize_script: |
    for type in Q8_0 Q2_K TQ1_0 TQ2_0 Q1_5_K Q2_K_S_NEW; do
      echo "Quantizing $type"
      ./build/bin/llama-quantize models/model-F16.gguf "models/model-${type}.gguf" "$type"
    done

  # Run perplexity and KLD
  perplexity_script: |
    mkdir -p results
    
    echo "Running Q8_0 Baseline..."
    ./build/bin/llama-perplexity \
      -m models/model-Q8_0.gguf \
      -f models/wikitext-2-raw/wiki.test.raw \
      --save-all-logits models/logits-Q8_0.kld \
      -t $(nproc) -ngl 0 2>&1 | tee results/ppl-Q8_0.txt
      
    for type in Q2_K TQ1_0 TQ2_0 Q1_5_K Q2_K_S_NEW; do
      echo "Running Perplexity for $type..."
      ./build/bin/llama-perplexity \
        -m "models/model-${type}.gguf" \
        -f models/wikitext-2-raw/wiki.test.raw \
        --kl-divergence --kl-divergence-base models/logits-Q8_0.kld \
        -t $(nproc) -ngl 0 2>&1 | tee results/ppl-${type}.txt
    done

  # Run benchmarks
  benchmark_script: |
    for type in Q8_0 Q2_K TQ1_0 TQ2_0 Q1_5_K Q2_K_S_NEW; do
      echo "Running Benchmark for $type..."
      ./build/bin/llama-bench \
        -m "models/model-${type}.gguf" \
        -t $(nproc) -ngl 0 -r 3 2>&1 | tee results/bench-${type}.txt
    done

  # Generate Report
  report_script: |
    TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    FILENAME_TS=$(date -u +%Y%m%d-%H%M%S)
    MODEL_SHORT="${MODEL_NAME}"
    mkdir -p benchmarks
    REPORT="benchmarks/benchmark-ARM-${MODEL_SHORT}-${FILENAME_TS}.md"
    
    {
      echo "# Quantization Benchmark Results (Cirrus CI ARM)"
      echo ""
      echo "**Model:** ${MODEL_REPO}"
      echo "**Date:** ${TIMESTAMP}"
      echo "**Runner:** ARM64 ($(nproc) cores)"
      echo ""
      echo "## Model Sizes"
      echo "| Type | BPW | Description |"
      echo "|------|-----|-------------|"
      echo "| Q8_0 | 8.50 | Baseline (high quality) |"
      echo "| Q2_K | 3.14 | Existing 2-bit k-quant |"
      echo "| TQ1_0 | 2.15 | Existing ternary |"
      echo "| TQ2_0 | 2.48 | Existing ternary |"
      echo "| **Q1_5_K** | **2.26** | **NEW: ternary-coded with 4-bit sub-block scales** |"
      echo "| **Q2_K_S_NEW** | **2.59** | **NEW: streamlined 2-bit quantization** |"
      echo ""
      echo "## Perplexity (WikiText-2) & KLD"
      echo "| Type | PPL | vs Q8_0 | Mean KLD |"
      echo "|------|-----|---------|----------|"
    } > $REPORT

    Q8_PPL=$(grep "Final estimate" results/ppl-Q8_0.txt | grep -oP 'PPL = \K[0-9.]+' || echo "N/A")
    echo "| Q8_0 | $Q8_PPL | baseline | 0 |" >> $REPORT
    
    for type in Q2_K TQ1_0 TQ2_0 Q1_5_K Q2_K_S_NEW; do
      PPL=$(grep "Final estimate" results/ppl-${type}.txt | grep -oP 'PPL = \K[0-9.]+' || echo "N/A")
      KLD=$(grep "Mean    KLD" results/ppl-${type}.txt | awk '{print $3}' || echo "N/A")
      DELTA=$(echo "$PPL - $Q8_PPL" | bc 2>/dev/null || echo "N/A")
      echo "| **$type** | **$PPL** | +$DELTA | $KLD |" >> $REPORT
    done
    
    {
      echo ""
      echo "## Performance (CPU-only, $(nproc) threads)"
      echo "| Type | Prompt (t/s) | Generation (t/s) |"
      echo "|------|-------------|------------------|"
    } >> $REPORT
    
    for type in Q8_0 Q2_K TQ1_0 TQ2_0 Q1_5_K Q2_K_S_NEW; do
      FILE="results/bench-${type}.txt"
      PP=$(grep -oP '\d+\.\d+ ± \d+\.\d+(?= t/s)' "$FILE" | head -1 || echo "N/A")
      TG=$(grep -oP '\d+\.\d+ ± \d+\.\d+(?= t/s)' "$FILE" | tail -1 || echo "N/A")
      echo "| $type | $PP | $TG |" >> $REPORT
    done
    
    cat $REPORT
    
  always:
    results_artifacts:
      path: "results/*"
